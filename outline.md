# RAG

Provides context that LLM wasnâ€™t trained on
Document database creation and text retrieval
Injects company-specific insights and expertise
Expands LLM knowledge base and improves accuracy
Topics covered:
Embeddings and their function
Chunking strategies for document preparation
Vector databases and options available
Storing documents in vector DBs
End-to-end RAG implementation
Similarity search and strategies
Prompt examples and summary lookup
Examples:
File ingestion and configuration
Document indexer and lookup

# Observability

Tracks LLM performance and optimizes prompts
Key topics:
Setting up LangSmith
Observing LLM calls
Building datasets and scoring
Human-in-the-loop for evaluations
Examples:
Health insurance chatbot
Local document chatbot
SQL evaluations
Image Gen

Reduces design costs
Creative uses beyond logos
Topics covered:
Overview of image generation tools
Prompts for image generation
Generating similar characters in images
Examples:
Swapping people in images
Creating logos

# RAG Data Ingestion

Querying databases without SQL
Pertinent data for LLM-driven results
Topics covered:
Text-to-SQL queries
Restructuring data for retrieval
Grouping tables into categories
Examples:
Querying large databases
Developer Productivity

GenAI apps for developers
Examples of top tools:
Cursor
Chat
Inline chat
Indexing docs/codebase
Tools walkthrough:
Agents
Ollama
LangChain

# Agents

AI workers completing tasks autonomously
Agent control and effectiveness
Topics covered:
Agentic lifecycle
ReAct prompt pattern
Building agents and function calling
Examples:
PBM chatbot
Wikipedia agent
LangGraph

AI graph components
Use cases and architecture
Multi-agent graph concept
Hierarchical teams
Examples:
Sales calls
News article summarizer
Fine Tuning

Reduces token usage and costs
Topics covered:
Fine-tuning process and pros/cons
Data preparation and model selection
Model merging and evaluation
Examples:
SQL DB fine-tuning
Review response generator